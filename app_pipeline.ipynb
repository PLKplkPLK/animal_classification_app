{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ff3d8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from PIL import Image\n",
    "from megadetector.detection.run_detector_batch import load_and_run_detector_batch\n",
    "\n",
    "from helpers import Deepfaune, crop_normalized_bbox_square, predict_batch, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ae29b",
   "metadata": {},
   "source": [
    "#### Settings and init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8afc782",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_directory = '../test_images'  # user input\n",
    "BATCH_SIZE = 30  # user input?\n",
    "BATCH_SIZE_MD = 14  # user input?\n",
    "N_CORES = 12  # user input?\n",
    "checkpoint_path = 'model/deepfaune_polish_lr4_checkpoint.pt' # user input in advanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9892d914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# images\n",
    "image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff', '.webp'}\n",
    "directory = Path(images_directory)\n",
    "images_paths = [\n",
    "    str(p) for p in directory.rglob(\"*\")\n",
    "    if p.suffix.lower() in image_extensions\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da6d1aa",
   "metadata": {},
   "source": [
    "#### Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36b78da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model v5a.0.1 already exists and is valid at /tmp/megadetector_models/md_v5a.0.1.pt\n",
      "PyTorch reports 1 available CUDA devices\n",
      "GPU available: True\n",
      "Warning: multiple cores requested, but a GPU is available; parallelization across GPUs is not currently supported, defaulting to one GPU\n",
      "PyTorch reports 1 available CUDA devices\n",
      "GPU available: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/plk/TOSHIBA EXT/animal_classification_app/venv/lib/python3.12/site-packages/yolov5/utils/general.py:31: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources as pkg\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading PT detector with compatibility mode classic\n",
      "Loaded image size 1280 from model metadata\n",
      "Using model stride: 64\n",
      "PTDetector using device cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Fusing layers... \n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n",
      "Model summary: 733 layers, 140054656 parameters, 0 gradients, 208.8 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model in 1.76 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:19<00:00,  2.38s/it]\n"
     ]
    }
   ],
   "source": [
    "results = load_and_run_detector_batch(\"MDV5A\", images_paths, confidence_threshold=0.2, batch_size=BATCH_SIZE_MD, n_cores=N_CORES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591387b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_paths_sec, categories, confs, bboxes, n_animals = [], [], [], [], []\n",
    "\n",
    "for result in results:\n",
    "    images_paths_sec.append(result.get('file'))\n",
    "    \n",
    "    detections = result.get('detections')\n",
    "    if detections:\n",
    "        detection = max(detections, key=lambda d: d[\"conf\"])\n",
    "        categories.append(detection.get('category'))\n",
    "        confs.append(detection.get('conf'))\n",
    "        bboxes.append(detection.get('bbox'))\n",
    "        n_animals.append(len(detections))\n",
    "    else:\n",
    "        categories.append(None)\n",
    "        confs.append(None)\n",
    "        bboxes.append(None)\n",
    "        n_animals.append(0)\n",
    "\n",
    "results_df = pd.DataFrame({'image_path': images_paths_sec, 'category': categories, 'conf': confs, 'bbox': bboxes, 'n_animals': n_animals})\n",
    "results_df.to_csv(f'megadetector_results.csv')\n",
    "\n",
    "with open('megadetector_raw_results.json', 'w') as output_file:\n",
    "    json.dump(results, output_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "65dd06af",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d8e47",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c4c997fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model in resolution 476x476\n",
      "CUDA available\n"
     ]
    }
   ],
   "source": [
    "# classifier model\n",
    "model_wrapper = Deepfaune(checkpoint_path)\n",
    "classifier = model_wrapper.model.base_model\n",
    "classifier.to('cuda')\n",
    "transforms = model_wrapper.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f325e810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%: 100 / 100\r"
     ]
    }
   ],
   "source": [
    "images = pd.read_csv('megadetector_results.csv', index_col=0)\n",
    "total=len(images)\n",
    "images['bbox'] = images[\"bbox\"].apply(\n",
    "    lambda b: ast.literal_eval(b) if isinstance(b, str) else None)\n",
    "\n",
    "batch = []\n",
    "paths = []\n",
    "results = pd.DataFrame({'image': [], 'detected_animal': [], 'confidence': []})\n",
    "ith_image = 0\n",
    "\n",
    "for _, row in images.iterrows():\n",
    "    ith_image += 1\n",
    "    print(f'{100*ith_image/total:.1f}%: {ith_image} / {total}', end='\\r')\n",
    "    image_path = row['image_path']\n",
    "\n",
    "    # only animals\n",
    "    category = row['category']\n",
    "    if category != 1:\n",
    "        results.loc[len(results)] = [image_path, 'empty', 0]\n",
    "        continue\n",
    "\n",
    "    # image\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        cropped_image = crop_normalized_bbox_square(image, row['bbox'])\n",
    "    except Exception as e:\n",
    "        # print(f'Error in image {image_path}: {e}')\n",
    "        continue\n",
    "\n",
    "    paths.append(image_path)\n",
    "    batch.append(cropped_image)\n",
    "\n",
    "    # run classifier every N images (e.g. 32)\n",
    "    if len(batch) == BATCH_SIZE:\n",
    "        preds = predict_batch(classifier, batch, transforms, class_names)\n",
    "        # if confidence (prediction[0][1]) is less than 0.1, classify as other\n",
    "        detections = [\n",
    "            prediction[0][0] if prediction[0][1] > 0.1 else 'other' for prediction in preds]\n",
    "        confs = [prediction[0][1] for prediction in preds]\n",
    "\n",
    "        batch_results = pd.DataFrame(\n",
    "            {'image': paths, 'detected_animal': detections, 'confidence': confs})\n",
    "        results = pd.concat([results, batch_results], ignore_index=True)\n",
    "        # if confidence less than threshold: other\n",
    "        batch = []\n",
    "        paths = []\n",
    "\n",
    "if len(batch) > 0:\n",
    "    preds = predict_batch(classifier, batch, transforms, class_names)\n",
    "    detections = [\n",
    "        prediction[0][0] if prediction[0][1] > 0.1 else 'other' for prediction in preds]\n",
    "    confs = [prediction[0][1] for prediction in preds]\n",
    "\n",
    "    batch_results = pd.DataFrame(\n",
    "        {'image': paths, 'detected_animal': detections, 'confidence': confs})\n",
    "    results = pd.concat([results, batch_results], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7373918",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now().strftime('%Y_%m_%d_%H_%M')\n",
    "results.to_csv(f'results_{now}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
